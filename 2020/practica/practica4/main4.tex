\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\input{../../tex/encabezado.tex}
\input{../../tex/tikzlibrarybayesnet.code.tex}

\usepackage{paracol}
%opening
\title{Práctica 1}
\author{Inferencia}

\begin{document}

\maketitle
% 
% \begin{abstract}
%  Este documento es un complemento de la charla ``Técnicas para calcular distribuciones de creencias honestas'' y tiene por objetivo servir de herramienta para introducirse en inferencia Bayesiana mediante problemas t\'ipicos, de dificultad variable, en sus aspectos pr\'acticos y te\'oricos. Si bien son varios ejercicios en la consigna, la idea es que hagan uno y el resto les quede.
% \end{abstract}


\section*{Elije tu propia aventura}

Elija un solo ejercicio ($a$ o $b$), y resu\'elvalo.

\begin{enumerate}
 \item \textbf{Flujo de inferencia en modelos generativos} (Secci\'on \ref{sec:flujo})
 \begin{enumerate}
  \item \textbf{Implementar} un modelo gr\'afico utilizando el software \texttt{samiam} y determinar cuándo un flujo de inferencia permanece abierto (Subsecci\'on \ref{subsec:flujo})
  \begin{enumerate}[i]
  \item Definir los factores del modelo gr\'afico visto en clase
  \item Extender el modelo gr\'afico
  \item Observar el efecto de los observables sobre las creencias a priori y a posteriori
  \item Determinar cu\'ando un flujo de inferencia permanece abierto
 \end{enumerate}
  \item \textbf{Derivar} algunas de las creencias a priori y creencias a posteriori mediante las reglas de la probabilidad (Subsecci\'on \ref{ssec:reglas})
 \end{enumerate}
 \item \textbf{Habilidad en la industria del video juego} (Secci\'on \ref{sec:trueskill})
 \begin{enumerate}
  \item \textbf{Implementar} una estimaci\'on de habilidad sobre jugadores en el lenguaje de programci\'on de su preferencia (Subsecci\'on \ref{ssec:estimacion})
  \begin{enumerate}[i]
  \item Utilizar la librer\'ia TrueSkill de python o la respectiva a su lenguaje de programaci\'on
  \item Simular un jugador con oponentes al azar utilizando el modelo generativo
  \item Estimar la habilidad del jugador, considerando conocidos a los opnentes, $\sigma=1$
  \item Repetir el punto ii y iii, y observar como var\'ian las observaciones 
 \end{enumerate}
  \item \textbf{Derivar} la verosimilitud, la evidencia y la posterior del modelo TrueSkill usando el sum-product algorithm sobre su factor graph (Subsecci\'on \ref{ssec:sum_product})
 \end{enumerate} 
 \item \textbf{Regresi\'on lineal Bayesiana} (Secci\'on \ref{sec:lineal})
 \begin{enumerate}
 \item \textbf{Implementar} una selección de modelo Bayesiana sobre datos simulados en el lenguaje de programaci\'on de su preferencia (Subsecci\'on \ref{ssec:seleccion})
 \begin{enumerate}[i]
  \item Definir la posterior, la verosimilitud y la evidencia de la regresi\'on lineal
  \item Simular datos con ruido provenientes de una sinoidal
  \item Ajustar regresiones polinomiales de grado 0 hasta 9 a los datos
  \item Seleccionar modelo basado en la evidencia
 \end{enumerate}
 \item \textbf{Derivar} la distribuci\'on de creencias a posteriori y la evidencia de la regresi\'on lineal Bayesiana (Subsecci\'on \ref{ssec:gaussiana})
\end{enumerate}
\end{enumerate}


\newpage  

\section{Flujo de inferencia en modelos generativos} \label{sec:flujo}

\subsection{Introducci\'on}

Hemos visto que las reglas \'optimas de razonamiento en contexto de incertidumbre son las llamadas ``reglas de la probabilidad'', la regla de la suma y regla del producto.
Estas son las \'unicas reglas que necesitamos para actualizar nuestras distribuciones de creencias.
Pero para eso necesitamos definir nuestro modelo generativo.

Si planteamos un modelo ``causal'' entre las variables para los que tenemos definidas sus distribuciones de creencia a priori, estaremos proponiendo lo que se conoce como modelo generativo.
El enfoque generativo es el m\'as completo pues permite definir la distribuci\'on de probabilidad conjunta y condicional, generar datos de esa distribuci\'on de probabilidad y separar la etapa de inferencia de la etapa de decisi\'on.

\vspace{0.3cm}

Variables del modelo ``entrevista de trabajo'':
\begin{itemize}
 \item[$a)$] La \textbf{admisi\'on} al trabajo depende del resultado $r$ de la entrevista
 \item[$r)$] El \textbf{resultado} depende de la dificultad $d$ de la entrevista y el rendimiento $p$ de la persona
 \item[$d)$] La \textbf{dificultad} es independiente. La mayor\'ia de las veces es dif\'icil, a veces f\'acil
 \item[$p)$] El \textbf{rendimiento} depende del nivel socio-econ\'omico $s$
 \item[$s)$] El \textbf{nivel socio-econ\'omico} de quienes se presentan est\'a dividido en mitades iguales
 \item[$c)$] \textbf{Informaci\'on externa} que depende del rendimiento, como puede ser la estimaci\'on Elo de habilidad en una p\'agina de juegos en l\'inea
\end{itemize}

\vspace{0.3cm}



\tikz{
    \node[invisible, xshift=8cm] () {};
    \node[invisible, xshift=-6.5cm] () {};
    \node[invisible, yshift=-3.5cm] () {};
    \node[invisible, yshift=2.5cm] () {};
    
    
    \node[det] (r) {$r$} ; %
    \node[det, above=of r, xshift=-1cm] (d) {$d$} ; %
    \node[det, above=of r, xshift=1cm] (p) {$p$} ; %
    \node[det, above=of p] (s) {$s$} ; %
    \node[det, below=of p, xshift=1cm] (c) {$c$} ; %
    
    \node[det, below=of r] (a) {$a$} ; %
    
    \node[const, xshift=3.4cm, yshift=1.8cm] (cpd_p) {
    \begin{tabular}{|l|l|l|}
        \hline
            & $p^0$ & $p^1$ \\ \hline
      $s^0$ & $0.90$ & $0.10$  \\ \hline
      $s^1$ & $0.50$ & $0.50$ \\ \hline
    \end{tabular}
    }; 
    
    
    \node[const, xshift=3cm, yshift=3.4cm] (cpd_s) {
    \begin{tabular}{|l|l|}
        \hline
        $s^0$ & $s^1$ \\ \hline
        $0.5$ & $0.5$  \\ \hline
    \end{tabular}
    }; 
    
    
    \node[const, xshift=-3cm, yshift=1.7cm] (cpd_p) {
    \begin{tabular}{|l|l|}
        \hline
        $d^0$ & $d^1$ \\ \hline
        $0.15$ & $0.85$  \\ \hline
    \end{tabular}
    }; 
    
    \node[const, xshift=-3.5cm, yshift=-1cm] (cpd_p) {
     \begin{tabular}{|c|c|c|c|}
        \hline 
        & $r^{-1}$ & $r^0$ & $r^1$ \\ \hline 
        ($p^0,d^0$) & $0.30$ & $0.40$ & $0.30$ \\ \hline
        ($p^0,d^1$) & $0.70$ & $0.25$ & $0.05$ \\ \hline
        ($p^1,d^0$) & $0.02$ & $0.08$ & $0.90$ \\ \hline
        ($p^1,d^1$) & $0.20$ & $0.30$ & $0.50$ \\ \hline
    \end{tabular}
    }; 
    
    \node[const, xshift=4.3cm] (cpd_c) {
    \begin{tabular}{|c|c|c|}
        \hline 
              & $c^0$ & $c^1$  \\ \hline 
        $p^0$ & $0.95$ & $0.05$ \\ \hline
        $p^1$ & $0.2$ & $0.8$ \\ \hline
    \end{tabular}
    }; 
    
    
    \node[const, xshift=2.4cm, yshift=-2cm] (cpd_a) {
    \begin{tabular}{|c|c|c|}
        \hline 
                 & $a^0$ & $a^1$  \\ \hline 
        $r^{-1}$ & $0.99$ & $0.01$ \\ \hline
        $r^0$    & $0.40$ & $0.60$ \\ \hline
        $r^1$    & $0.10$ & $0.90$ \\ \hline
    \end{tabular} 
    }; 
    
    \edge {d,p} {r};
    \edge {p} {c};
    \edge {r} {a};
    \edge {s} {p};
 }

Al definir un modelo gr\'afico estamos definiendo una distribuci\'on de probabilidad conjunta $P(s,d,p,r,c,a)$.

\subsection{Flujos de inferencia} \label{subsec:flujo}

¿Qué pasa con nuestras creencia sobre las diferentes variables ocultas cuando observamos algunas de ellas?.
Si bien podr\'iamos resolver este problema a mano, aplicando las reglas de la suma y del producto, en este primer ejercicio el objetivo es implementar el modelo gr\'afico en alg\'un software que nos permita jugar con los distintos flujos de inferencia y verificar r\'apidamente si la veracidad de la siguiente tabla.
El objetivo es adquirir intuici\'on respecto de la apertura de los flujos de inferencia en los modelos causales.

\begin{table}[H]
\centering
 \begin{tabular}{c c|c}
          & $V \notin \text{Observable} $ &  $V \in \text{Observable} $ \\
 $X \rightarrow V \rightarrow Y $    &  S\'i & No \\ 
 $X \leftarrow V \leftarrow Y $      &  S\'i & No \\ 
 $X \leftarrow V \rightarrow Y $     &  S\'i & No \\
 $X \rightarrow V \leftarrow Y $     & $\underbrace{\text{No}}_{\hfrac{\text{\tiny Y ning\'un descendiente}}{ \text{\tiny observable}}}$ &  $\underbrace{\text{S\'i}}_{\hfrac{ \text{\tiny O alg\'un descendiente}}{ \text{\tiny observable}}}$
 \end{tabular} 
\end{table}

Pueden utilizar el software de su preferencia.
Sin embargo, para esta tarea proponemos el software \texttt{samiam} dado que es muy \'util para visualizar el efecto de la evidencia sobre los distribuciones de creencia.
Lo pueden descargar en \url{http://reasoning.cs.ucla.edu/samiam/} y no requiere permisos especiales.

\vspace{0.3cm}

Si deciden usar el software \texttt{samiam}, en el repositorio hay un archivo con el modelo implementado parcialmente.
Solamente falta agregar la variable ``nivel socio-econ\'omico'' ($s$), la relaci\'on causal sobre el rendimiento ($p$) y actualizar las distribuci\'on condicionales de ambas variables.

Una vez editado el modelo, pasen a modo ``inferencia'' seleccionando \texttt{Mode>Query Mode}. Abran todas las distribuciones de creencias seleccionando \texttt{Query>Show monitors>Show All} y diviertanse eligiendo observables.

\subsection{Reglas de la suma y el producto} \label{ssec:reglas}

Para entender el motivo por el cual los flujos se abren y se cierran es un buen ejercicio calcular las creencias a priori y a posteriori aplicando a mano las reglas de la suma y el producto.
La regla de la suma dice que nuestra creencia marginal se puede calcular integrando la distribuci\'on de creencias conjunta.

\begin{equation}
 P(X) = \sum_Y P(X,Y) 
\end{equation}

La regla del producto nos dice que la distribuci\'on de creencia conjunta se puede expresar como una multiplicaci\'on de distribuciones creencia unidimensionales.

\begin{equation}
P(X,Y) = P(Y|X) P(X) 
\end{equation}

Elija usted las creencia a priori y a posteriori que quiera.
Si no se le ocurre, le proponemos computar lo siguiente:

\begin{itemize}
 \item $P(d^0|c^0)$
 \item $P(d^0|c^0,a^1)$
 \item $P(a^1|p^0)$
 \item $P(a^1|c^0,p^0)$
 \end{itemize}  

\section{Habilidad en la industria del video juego} \label{sec:trueskill}

\subsection{Introducci\'on}


TrueSkill es el estado del arte para estimaci\'on de habilidad en la industria del video juego.
Es una versión Bayesiana del modelo desarrollado por Arpad Elo en 1959, usado por la federaci\'on internacional de ajedrez desde 1970.
La idea principal consiste en considerar los resultados observables $r$ en funci\'on de rendimientos ocultos $p$ de los jugadores, variables aleatorias centradas en la verdadera habilidad $s$.

\begin{figure}[H]
\centering 
\tikz{ %
        
        \node[det, fill=black!10] (r) {$r_{ij}$} ; %
        \node[const, left=of r, xshift=-1.4cm] (r_name) {\small Resultado observado ($r$)}; 
        \node[const, right=of r] (dr) {\large $ r_{ij} = \mathbb{I}(p_i>p_j)$};  
         \node[latent, above=of r, xshift=-0.8cm] (p1) {$p_i$} ; %
         \node[latent, above=of r, xshift=0.8cm] (p2) {$p_j$} ; %
         \node[const, left=of p1, xshift=-0.55cm, yshift=0.2cm] (p_name) {\small Rendimiento aleatorio oculto ($p$)}; 
         \node[const, left=of p1, xshift=-0.55cm, yshift=-0.2cm] (p_name) {\small centrado en la verdadera habilidad ($s$)}; 
         
         \node[const, right=of p2] (dp2) {\large $p \sim N(s,\beta^2)$};
         
         \edge {p1,p2} {r};
         
         \node[invisible, right=of p2, xshift=4.75cm] (s-dist) {};
} 
\end{figure}

El modelo supone que la persona ganadora es aquella que tuvo mayor rendimiento en la partida.
Esto permite inferir qui\'en tuvo mayor rendimiento y por lo tanto calcular la probabilidad de que ese evento ocurra.
En t\'erminos gr\'aficos, la probabilidad del resultado dada las estimaciones previas es
\begin{equation}
P (p_i > p_j | s_i^\text{old} , s_j^\text{old} )
\end{equation}

La probabilidad de ganar de un jugador y de otro, en t\'erminos gr\'aficos, es equivalente al volumen debajo de la curva de una lado y del otro del recta $p_i=p_j$

\begin{figure}[H]     
     \centering
     \begin{subfigure}[b]{0.45\textwidth}
       \includegraphics[width=1\textwidth]{../../figures/probaOfWin_2D.pdf} 
     \end{subfigure}
\end{figure}

\subsubsection{Estimaci\'on puntual}

La soluci\'on propuesta por Elo fue comenzar con una estimaciones iniciales arbitrarias, que son luego son actualizadas de la siguiente forma, 

\begin{equation*}
s_i^{\text{new}} = s_i^{\text{old}} + K \Delta
\end{equation*}

donde,

\begin{equation*}
\Delta = \underbrace{(2\,\mathbb{I}(p_i>p_j)-1)}_{\hfrac{\textbf{\tiny Signo}} {\text{\tiny del resultado}}} \, \underbrace{(1 - P(p_i>p_j|s_i,s_j))}_{\hfrac{\textbf{\tiny Sorpresa}}{\text{\tiny del resultado}}}
\end{equation*}

El modelo de soluci\'on del sistema Elo 


\begin{figure}[H]
\centering
\tikz{ %        
        \node[const] (e) {Estimaci\'on}; 
        \node[const, xshift=3cm] (p) {Predicci\'on}; 
        \node[const, xshift=1.5cm, yshift=-1cm] (s) {Sorpresa}; 
         \edge {e} {p};
         \edge {p} {s};
         \edge {s} {e};
         \node[invisible, right=of p, xshift=1.2cm] (s-dist) {};
} 
\end{figure}

El problema principal es la falta de incertidumbre respecto de las estimaciones.
La estimaci\'on inicial arbitraria no puede tener el mismo estatus que aquella estimada luego de varias partidas.
Este problema fue resuelto mediante la constante $K$.
Sin ella, lo que pierde un jugador lo gana el otro.
En la pr\'actica a jugadores con muchas partidas se le asigna $K$ bajos, y a jugadores con pocas partidas valores altos.
Sin embargo, esta es una soluci\'on ad-hoc.

\subsubsection{Distribuci\'on de creencias}

Un tratamiento correcto de la incertidumbre necesariamente requiere la incorporaci\'on de una distribuci\'on de creencias sobre las habilidades.

\begin{figure}[H]
\tikz{ %
        
        \node[det, fill=black!10] (r) {$r_{ij}$} ; %
        \node[const, left=of r, xshift=-1.4cm] (r_name) {\small Resultado observado ($r$)}; 
        \node[const, right=of r] (dr) {\large $ r_{ij} = \mathbb{I}(p_i>p_j)$}; 
          
         \node[latent, above=of r, xshift=-0.8cm] (p1) {$p_i$} ; %
         \node[latent, above=of r, xshift=0.8cm] (p2) {$p_j$} ; %
         \node[const, left=of p1, xshift=-0.55cm, yshift=0.2cm] (p_name) {\small Rendimiento aleatorio oculto ($p$)}; 
         \node[const, left=of p1, xshift=-0.55cm, yshift=-0.2cm] (p_name) {\small centrado en la verdadera habilidad ($s$)}; 
         
         \node[latent, above=of p1] (s1) {$s_i$} ; %
         \node[latent, above=of p2] (s2) {$s_j$} ; %
                  
         \node[const, right=of p2] (dp2) {\large $p \sim N(s,\beta^2)$};
         
         \node[const, right=of s2] (ds2) {\large $s \sim N(\mu,\sigma^2)$};
         
          \node[const, left=of s1, xshift=-.85cm, yshift=0.2cm] (s_name) {\small Distribuci\'on de creencias}; 
          \node[const, left=of s1, xshift=-.85cm, yshift=-0.2cm] (s_name) {\small sobre la habilidad oculta}; 
%          
         \edge {p1,p2} {r};
         \edge {s1} {p1};
         \edge {s2} {p2};
         
         \node[invisible, right=of p2, xshift=4.75cm] (s-dist) {};
} 
\end{figure}

Una distribuci\'on de creencias a priori con poca informaci\'on deber\'a tener mucha varianza alrededor de la media de habilidades de la poblaci\'on.
Del mismo modo que en el modelo gr\'afico discreto visto en la secci\'on anterior, las distribuciones de creencia a posteriori y la evidencia no son m\'as que las consecuencia de aplicar las reglas de la suma y el producto.
Usando las reglas de la probabilidad podemos probar que la evidencia, o predicci\'on a priori del dato observado, es

\begin{equation}
 P(r_{12}=1|s_1,s_2) = 1-\Phi(0| \underbrace{\mu_1 - \mu_2}_{ \hfrac{\text{Diferencia}}{\text{esperada}} \, \delta }, \underbrace{\sigma_1^2 + \sigma_2^2 + 2\beta^2}_{\hfrac{\text{Varianza}}{\text{total}} \, \vartheta^2 })
 \end{equation}
\begin{center}
\includegraphics[width=0.49\textwidth]{../../figures/evidence} 
\end{center}

y en caso perdedor

\begin{equation}
 P(r_{12}=0|s_1,s_2) = \Phi(0| \delta, \vartheta^2)
 \end{equation}

Luego de ver un resultado, la posterior anal\'itica para el caso ganador es

\begin{equation}
\overbrace{P(s_1 \mid r)}^{\text{Posteriori}} \propto \overbrace{N(s_1 \, | \, \mu_1, \sigma_1^2) }^{\text{Priori}} \, \overbrace{1-\Phi(0 \, | s_1 - \mu_2 , \vartheta^2 - \sigma_1^2)}^{\text{Verosimilitud}}  \ \  \text{Caso ganador} 
\end{equation}

donde $Phi$ representa la acumulada de la distribuci\'on Gaussiana.
Del mismo modo, la evidencia para el caso perdedor es,

\begin{equation*}
\overbrace{P(s_2 \mid r)}^{\text{Posteriori}} \propto \overbrace{N(s_2 \, | \,\mu_2, \sigma_2^2) }^{\text{Priori}} \, \overbrace{\Phi(0  \, | \mu_1 - s_2, \vartheta^2 - \sigma_1^2)}^{\text{Verosimilitud}}  \ \  \text{Caso perdedor} 
\end{equation*}

\begin{figure}[H]
\begin{subfigure}[b]{0.49\textwidth}
 \includegraphics[page=6,width=1\textwidth]{../../figures/posterior_win}
 \caption{Caso ganador}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
\includegraphics[width=1\textwidth]{../../figures/posterior_loose}
\caption{Caso perdedor}
\end{subfigure}
\end{figure}

Notar que la distribuci\'on a priori, por ser una distribuci\'on de probabilidades, integra $1$. Y que la distribuci\'on proporcional a la posteriori integra la evidencia.
Adem\'as notar que la verosimilitud, al ser la acumulada de la distribuci\'on Gaussiana, va de $0$ a $1$ y cumple la funci\'on de filtro de la distribuci\'on de creencias a priori.
En las regiones donde la verosimilitud es $1$, la posterior y el prior permanecen iguales.
En las regiones donde la verosimilitud es $0$, la posterior se anula.
Si bien a simple vista la distribuci\'on a posteriori aparenta se una distribuci\'on Gaussiana, por su asimetr\'ia sabemos que no lo es.

\paragraph{Aproximaci\'on variacional de la posterior}

Si bien podemos calcular la distribuci\'on a posteriori exacta, en la pr\'actica es preferible aproximarla por una distribuci\'on Gaussiana de modo de tener una soluci\'on anal\'itica eficiente.
A este perspectiva de aproximar la posterior mediante una distribuciones que pertenece a cierta familia, se la conoce como variacional.\footnote{La aproximaci\'on variaicional es uno de los $3$ m\'etodos para computar distribuciones de creencia a posteriori, junto a las soluciones anal\'iticas exactas y los m\'etodos de muestreo. Debido a su versatilidad y eficiencia, es el m\'etodo utilizado para desarrollar redes neuronales Bayesianas. Ver los videos Summer School on Deep Learning and Bayesian Methods organizados por \href{https://deepbayes.ru/}{Deep Bayes (link)}.}

\subsection{Estimaci\'on de habilidades sint\'eticas}\label{ssec:estimacion}

La mayor parte de los lenguajes de programaci\'on tienen alguna librer\'ia que implementa la soluci\'on variacional del modelo de habilidad, generalmente denominada \texttt{trueskill}.
Para ganar conocer el comportamiento de TrueSkill proponemos realizar un experimento con datos simulados.
El objetivo es verificar cu\'anto tarda TrueSkill en estimar la verdadera habilidad y cu\'al es la variabilidad de sus estimaciones.

Para ello proponemos el siguiente diseño experimental: 

\begin{itemize}
 \item[$\mu_1)$] Definimos al comienzo la habilidad real del jugador focal, alg\'un valor entre $ \mu_1 \in \{15,20,30,35\}$
 \item[$\mu_2)$] El cual se va a enfrentar a 50 oponentes al azar con habilidad real ($\mu_2 \sim N(25,\frac{25}{3})$) en partidas 1 vs 1
 \item[$\beta$, $p$)] Cuando compiten, ambos ``tiran la moneda de su rendimiento'' de una distribuci\'on Gaussiana centrada en su propia habilidad y con cierto ruido, $p \sim N(\mu,\beta)$. Probar $\beta=\frac{25}{6}$.
 \item[$r_{12})$] El resultado (ganador o perdedor) que surge de determinar qui\'en obtuvo mayor rendimiento, se utilizar\'a para actualizar la distribuci\'on de creencias sobre las habilidades
 \item[$\sigma_1)$] La incertidumbre inicial sobre la habilidad del jugador focal queremos que sea alta, por ejemplo $\sigma_1 = \frac{25}{3}$
 \item[$\sigma_2)$] La incertidumbre respecto de la habilidad de los oponentes la vamos a considerar baja, por ejemplo $\sigma_2=1$
\end{itemize}

Para ver la velocidad de convergencia de y la variabilidad en la estimaci\'on, repetir el experimento 50 veces.

\subsection{Sum-product algorithm}\label{ssec:sum_product}

La actualizaci\'on de creencias relativas al modelo de habilidad Bayesiano depende de las reglas de la suma y el producto.
El sum-product algorithm es una t\'ecnica eficiente de pasaje de mensajes para computar distribuciones de creencias a posteriori a partir factor graph, i.e. modelos gr\'aficos en el que las probabilidades condicionales aparecen como un nodo diferenciado al nodo variable t\'ipico de las redes Bayesianas.

\vspace{0.3cm}

\columnratio{0.4}
\begin{paracol}{2}
\includegraphics[width=0.28\textwidth]{../../figures/elo-factor-es_d}     

\switchcolumn

\vspace{0.25cm}

Las marginales en un factor graph se calculan como el producto de los mensajes recibidos por los nodos vecinos

\begin{equation*}
P(x) = \prod_{h \in n(x)} m_{h \rightarrow x} 
\end{equation*} 

donde

\begin{center}
$m_{x \rightarrow f}(x)$ : Mensaje de variable $x$ a factor $f$ \\[0.2cm]
 $m_{f \rightarrow x}(x)$ : Mensaje factor $f$ a variable $x$\\[0.2cm]
 $n(v)$ : Conjunto de nodos vecinos del nodo $v$
\end{center}


\begin{equation*}
m_{x \rightarrow f}(x) = \prod_{h \in n(x) \setminus \{f\} } m_{h \rightarrow x}(x) 
\end{equation*}

\begin{equation*}
 m_{f \rightarrow x}(x) = \int \Big( f(X) \prod_{h \in n(f) \setminus \{x\} } m_{h \rightarrow f}(h) \Big) dX_{\setminus \{x\}}
\end{equation*}


 \end{paracol}

 \vspace{0.25cm}

Para calcular la evidencia y la posterior del modelo de habilidad es suficiente con aplicar el pasaje de mensajes definido por el sum-product algorithm junto a las siguientes propiedades

\begin{description}
 \item[Simetr\'ia:]  $N(x|\mu,\sigma^2) = N(\mu|x,\sigma^2) = N(-\mu|-x,\sigma^2) = N(-x|-\mu,\sigma^2) $
 \item[Estandar:] $N(x|\mu,\sigma^2) = N( \frac{X-\mu}{\sigma} | 0,1)$
 \item[Acumulada:] $\frac{\partial}{\partial x} \Phi(x|\mu,\sigma^2) = N(x|\mu,\sigma^2)$
 \item[Indicadora:]  $\iint_{-\infty}^{\infty}  \mathbb{I}(x=h(y,z)) \, f(x) \,  g(y)\, dx\, dy = \int_{-\infty}^{\infty} f(h(y,z)) \, g(y) \, dy $
 \item[Producto:] $\int_{-\infty}^{\infty} N(x|\mu_x,\sigma_x^2)N(x|\mu_y,\sigma_y^2) \, dx  = \int_{-\infty}^{\infty}  \underbrace{N(\mu_x|\mu_y,\sigma_x^2+\sigma_y^2)}_{\text{constante}} \underbrace{ N(x|\mu_{*},\sigma_{*}^2) dx}_{\text{integra } 1} $
\end{description}


\section{Modelo lineal Bayesiano} \label{sec:lineal}

\subsection{Introducci\'on}

Cuando hablamos de modelos lineal nos referimos a funciones $\bm{t}= f(\bm{w},\bm{x}) + \epsilon $ que son lineales en sus parámetros $\bm{w}$, no en sus observables $\bm{x}$.
Utilizando transformaciones no lineales sobre los observables, $\bm{\phi}(\bm{x})$, es posible modelar cualquier tipo de relaci\'on no lineal entre los observables $\bm{x}$ y los no observables $\bm{t}$ mediante funciones lineales en los par\'ametros $\bm{w}$.

\vspace{0.3cm}

El modelo lineal es un modelo generativo. Propone la existencia de una relaci\'on causal $y(\cdot)$ entre una variable de inter\'es (target) $t$ y los vectores de variables observables $\bm{x}$ y no observables $\bm{w}$.
En t\'erminos generales la relaci\'on causal, $y(\cdot)$ se define como,

\begin{equation}
y(\bm{x},\bm{w}) = \sum_{i=0}^{M-1} w_i \phi_i(\bm{x}) = \bm{w}^T \bm{\phi}(\bm{x})
\end{equation}
 
Donde el vector $\bm{\phi}(\vm{x}_1) = ( \phi_0(\bm{x}_1), \, \phi_1(\bm{x}_1) , \, \dots , \, \phi_{M-1}(\bm{x}_1) )^T$ son la $M$ transformaciones no-lineales.
Notar que cada funci\'on de base $\phi_j(\cdot)$ recibe el vector-input completo $\bm{x}_i$.
Hoy trabajaremos con una \'unica dimensi\'on, por lo que el vector $\bm{x}_i$ ser\'a simplemente un escalar.
Aqu\'i usamos la convenci\'on $\phi_0(\bm{x})=1$.
El modelos lineal m\'as simple es aquel que tambi\'en es lineal en sus variables observables $\bm{x}$.
En este caso la transformaciones no es m\'as que la identidad $\bm{\phi}(\bm{x})=\bm{x}$.

Adem\'as de la parte estrictamente causal, el modelo lineal considera siempre la existencia de un factor aleatorio $\epsilon$.
El modelo completo que relaciona la variable de inter\'es $t$ con las variables observables $\bm{x}$ se compone de ambos t\'erminos.

\begin{equation}
 t = y(\vm{x},\vm{w}) + \epsilon
\end{equation}
 
El ruido aleatorio $\epsilon$ lo vamos a modelar proviniendo de una distribuci\'on Gaussiana, centrada en cero y precisi\'on (inversa de la varianza) $\beta$, $\epsilon \sim N(0,\beta^{-1})$.
\footnote{Una pregunta que surge naturalmente es plantearse si las decisiones que tomamos para modelar la relaciones entre variables es la correcta.En este punto no hay que perder de vista que los modelos no son m\'as que representaciones de la realidad, as\'i como los mapas no son el territorio.
Esto no significa que sean todas igualmente falsas y desechables.
Hay representaciones mejores que otras.
Y la inferencia Bayesiana prove\'e una forma de computar la creencias \'optimas sobre los modelos dada la evidencia.
Entonces terminemos de desarrollar la estructura de la familia de modelos lineales y dejemos la selecci\'on de modelos para despu\'es.}

Dado que tenemos una sola componente determinista $y(\cdot)$ y una sola componente aleatorio $\epsilon$, el modelo generativo de las variables de inter\'es $t$ es,
\begin{equation}
P(t | \bm{x}, \bm{w}, \beta) = \N(t | y(\bm{x},\bm{w}), \beta^{-1}) = \N(t | \bm{w}^T \bm{\phi}(\bm{x}) , \beta^{-1})
\end{equation}

% Planteado en t\'etminos gr\'aficos,
% 
% \begin{figure}[H]
%     \centering
%     \tikz{
% 
%     \node[latent, fill=black!100, minimum size=2pt] (x) {} ; %
%     \node[const, right=of x] (c_x) {$\vm{x}$};
%     \node[latent, fill=black!20, yshift=-1.5cm] (t) {$t$} ; %
%     \node[latent, fill=black!100, yshift=-1.5cm , xshift=-2cm,minimum size=2pt] (beta)
%     {} ; %
%     \node[const, above=of beta] (c_beta) {$\beta$};
%     \node[latent, fill=black!0, yshift=-1.5cm, xshift=2cm] (w) {$\vm{w}$};
%     \node[latent, fill=black!100, xshift=2cm, minimum size=2pt] (alpha) {} ; %
%     \node[const, right=of alpha] (c_alpha) {$\alpha$};
%     
%     \edge {x,beta,w} {t};
%     \edge {alpha} {w};
%     
%     \node[invisible, fill=black!0, minimum size=0pt, xshift=-0.52cm] (data_inv) {} ; %
%       
%     }  
% \end{figure}
% 

Generalmente se supone que las variables de inter\'es $t$ son independiente e id\'enticamente distribuida, por lo que la probabilidad conjunta de un vector de variables de inter\'es $\bm{t}$ se obtiene como la multiplicaci\'on de cada uno de los t\'erminos individuales

\begin{equation}
P(\bm{t} | \bm{x}, \bm{w}, \beta) = \prod_{i=1}^n \N(t_i | \bm{w}^T \bm{\phi}(\bm{x}_i) , \beta^{-1})
\end{equation}

% En t\'erminos gr\'aficos
% 
% 
% \begin{figure}[H]
%     \centering
%     \tikz{
% 
%     \node[latent, fill=black!100, minimum size=2pt] (x) {} ; %
%     \node[const, right=of x] (c_x) {$\vm{x}_n$};
%     \node[latent, fill=black!20, yshift=-1.5cm] (t) {$t_n$} ; %
%     \node[latent, fill=black!100, yshift=-1.5cm , xshift=-2cm,minimum size=2pt] (beta)
%     {} ; %
%     \node[const, above=of beta] (c_beta) {$\beta$};
%     \node[latent, fill=black!0, yshift=-1.5cm, xshift=2cm] (w) {$\vm{w}$};
%     \node[latent, fill=black!100, xshift=2cm, minimum size=2pt] (alpha) {} ; %
%     \node[const, right=of alpha] (c_alpha) {$\alpha$};
%     
%     \edge {x,beta,w} {t};
%     \edge {alpha} {w};
%     
%     \node[invisible, fill=black!0, minimum size=0pt, xshift=-0.52cm] (data_inv) {} ; %
%     \plate {data} {(t)(x)(c_x)(data_inv)} {$N$}; %
%       
%     }  
% \end{figure}

Tambi\'en podemos representar $N$ distribuciones Gaussianas independientes a trav\'es de una \'unica distribuci\'on Gaussiana multivariada, en la que la matriz de covarianzas solo tiene valores no nulos en la diagonal.

\begin{equation}
P(\bm{t} | \bm{x}, \bm{w}, \beta) = \prod_{i=1}^n \N(t_i | \bm{w}^T \bm{\phi}(\bm{x}_i) , \beta^{-1}) = \N(\bm{t}|\bm{w}^T \bm{\Phi}, \beta^{-1} \vm{I})
\end{equation}

Donde $\vm{I}$ es la matriz identidad y $\bm{\Phi}$ se la matriz de diseño

\begin{equation}
 \bm{\Phi} =
  \begin{pmatrix}
    \phi_0(\bm{x}_1) & \phi_1(\bm{x}_1) & \dots & \phi_{M-1}(\bm{x}_1)\\
    \vdots & \vdots & \ddots & \vdots \\
    \phi_0(\bm{x}_N) & \phi_1(\bm{x}_N) & \dots & \phi_{M-1}(\bm{x}_N)
  \end{pmatrix}
  = 
  \begin{pmatrix}
   \bm{\phi}(\vm{x}_1)^T \\
   \vdots \\
   \bm{\phi}(\vm{x}_N)^T \\
  \end{pmatrix}
\end{equation}


\subsubsection{Estimaci\'on cl\'asica}

La soluci\'on cl\'asica, o frecuentista, elige los par\'ametros $\bm{w}$ que tienen máxima verosimilitud.

\begin{equation}
 \bm{w}_\text{MV} = \underset{\bm{w}}{\text{ max }} p(\bm{t} | \bm{x}, \bm{w}, \beta)
\end{equation}

Los par\'ametros $\bm{w}$ que minimizan la distancia entre la curva $\bm{w}^T\bm{\phi}(\bm{x}_i)$ y los datos $\bm{t}$ son los que tienen mayor verosimilitud (demostraci\'on en el anexo).

\begin{equation}
 \underset{\bm{w}}{\text{ max }} P(\bm{t} | \bm{x}, \bm{w}, \beta) = \underset{\bm{w}}{\text{ min }} \sum_{i=1}^{n}  (t_i - \bm{w}^T\bm{\phi}(\bm{x}_i))^2 
\end{equation}

Aumentar la flexibilidad de la curvas $\bm{w}^T\bm{\phi}(\bm{x}_i)$ a trav\'es de modelos m\'as complejos, e.g. aumentando el grado de los modelos polinomiales, siempre permite reducir la distancia a los datos.
Este enfoque conduce a un problema conocido como over-fitting (o sobreajuste).
Las estrategias comunes para evitar el sobreajuste son, o agregar a la verosimilitud t\'erminos ad-hoc que penalicen la complejidad del modelo, o evaluando la verosimilitud en conjuntos de datos de validaci\'on distintos a los de entrenamiento.

\subsubsection{Estimaci\'on Bayesiana}

Aqu\'i veremos como un tratamiento Bayesiano de la regresi\'on linea no solo evita el over-fitting que surge del criterio de estimaci\'on puntual basado en m\'axima verosimilitud, sino que ofrece una forma natural para seleccionar la complejidad del modelo usando tan solo los datos de entrenamiento.

\vspace{0.3cm}

Antes de computar nuestra distribuci\'on de creencias a posteriori sobre los par\'ametros $\bm{w}$ es necesario definir la distribuci\'on de creencias a priori.

\begin{equation}
 p(\vm{w}) = N(\vm{w}| \vm{0}, \alpha^{-1} \vm{I})
\end{equation}

Dada la elecci\'on de una distribuci\'on Gaussiana a priori, la distribuci\'on a posteriori tambi\'en ser\'a Gaussiana.
Esto surge de derivar de completar los cuadrados en el exponente y encontrar luego el coeficiente de normalizaci\'on.
El resultado general se encuentra en la ecuaci\'on (\ref{eq:post}) y es lo \'unico que se necesita para derivar la posteriori y la evidencia.
La distribuci\'on posteriori sobre $\vm{w}$ tiene como media

\begin{equation}
 \vm{m}_N = \beta  \vm{S}_N\vm{\Phi}^T \vm{t}
\end{equation}

y como covarianzas

\begin{equation}
 \vm{S}_N^{-1} = \alpha \vm{I} + \beta \vm{\Phi}^T\vm{\Phi}
\end{equation}

Esta soluci\'on anal\'itica considera a $\beta$ como constante conocida.
Y como en los problemas de regresi\'on no buscamos inferir la distribuci\'on del vector de entrada $\vm{x}$, este t\'ermino tambi\'en lo podemos tratar como constante conocida.
Luego, el modelo gr\'aficos es, 

\begin{figure}[H]
    \centering
    \tikz{

    \node[latent, fill=black!100, minimum size=2pt] (x) {} ; %
    \node[const, right=of x] (c_x) {$\vm{X}$};
    \node[latent, fill=black!20, yshift=-1.5cm] (t) {$\bm{t}$} ; %
    \node[latent, fill=black!100, yshift=-1.5cm , xshift=-2cm,minimum size=2pt] (beta)
    {} ; %
    \node[const, above=of beta] (c_beta) {$\beta$};
    \node[latent, fill=black!0, yshift=-1.5cm, xshift=2cm] (w) {$\vm{w}$};
    \node[latent, fill=black!100, xshift=2cm, minimum size=2pt] (alpha) {} ; %
    \node[const, right=of alpha] (c_alpha) {$\alpha$};
    
    \edge {x,beta,w} {t};
    \edge {alpha} {w};
    
    \node[invisible, fill=black!0, minimum size=0pt, xshift=-0.52cm] (data_inv) {} ; %
      
    }  
\end{figure}

Y la evidencia del modelo es

\begin{equation}
 P(t) = \N(\bm{t}| \vm{0}, \beta^{-1} \vm{I} + \alpha^{-1}\bm{\Phi}\bm{\Phi}^T  )
\end{equation}

A modo de visualizaci\'on, mostramos que ocurre con las creencias sobre la ordenada al origen y la pendiente de un modelo lineal a medida que van llegando datos.

 \begin{figure}[H]
\begin{subfigure}[t]{0.32\textwidth} 
\caption*{Verosimilitud} 
\end{subfigure}
\begin{subfigure}[t]{0.32\textwidth}
\caption*{Priori/Posteriori} 
\includegraphics[width=\textwidth]{../../figures/linearRegression_posterior_0.pdf} 
\end{subfigure}
\begin{subfigure}[t]{0.32\textwidth}
\caption*{Espacio de datos} 
\includegraphics[width=\textwidth]{../../figures/linearRegression_dataSpace_0.pdf} 
\end{subfigure}

\begin{subfigure}[c]{0.32\textwidth}
\includegraphics[width=\textwidth]{../../figures/linearRegression_likelihood_1.pdf} 
\end{subfigure}
\begin{subfigure}[c]{0.32\textwidth}
\includegraphics[width=\textwidth]{../../figures/linearRegression_posterior_1.pdf} 
\end{subfigure}
\begin{subfigure}[c]{0.32\textwidth}
\includegraphics[width=\textwidth]{../../figures/linearRegression_dataSpace_1.pdf} 
\end{subfigure}

\begin{subfigure}[c]{0.32\textwidth}
\includegraphics[width=\textwidth]{../../figures/linearRegression_likelihood_2.pdf} 
\end{subfigure}
\begin{subfigure}[c]{0.32\textwidth}
\includegraphics[width=\textwidth]{../../figures/linearRegression_posterior_2.pdf} 
\end{subfigure}
\begin{subfigure}[c]{0.32\textwidth}
\includegraphics[width=\textwidth]{../../figures/linearRegression_dataSpace_2.pdf} 
\end{subfigure}
\end{figure}

\subsection{Selecci\'on de modelo}\label{ssec:seleccion}

Cada vez que resolvemos a un problema de regresi\'on tenemos muchos modelos alternativos que podr\'iamos usar.
Para decidir sobre los distintos modelos, siempre es buena idea pensar en t\'erminos Bayesianos.
En este caso podemos computar cu\'al es nuestra distribuci\'on de creencias sobre los modelos dados los datos.

\begin{equation*}
 P(\text{M}|\text{D}) = \frac{P(\text{D}|\text{M})P(\text{M})}{ P(\text{D})}
\end{equation*}

En este caso no es posible calcular el denominador $P(\text{D})$, pero al comparar modelos este t\'ermino se cancela.

\begin{equation*}
  \frac{P(\text{M}_i|\text{D})}{P(\text{M}_j|\text{D})}  = \frac{P(\text{D}|\text{M}_i)\,P(\text{M}_i)}{ \underbrace{P(\text{D}|\text{M}_j)}_{\text{Evidencia!}}P(\text{M}_j)}  
\end{equation*}

Para comparar modelos solo necesitamos la predicci\'on a priori de los datos observados, es decir, su evidencia.
La predicci\'on a priori, al ser una distribuci\'on de probabilidad que integrar 1, sufre una penalizaci\'on natural a medida que se le agregan dimensiones a los modelos.

\begin{figure}[H]
\centering
  \includegraphics[width=0.6\textwidth]{../../figures/evidencia_de_modelos_alternativos} 
\end{figure}

Para verificar la utilidad de la evidencia (predicci\'on a priori de los datos observados), les proponemos realizar el siguiente experimento.

\begin{itemize}
  \item Generar datos de una sinoidal en el intervalo $[-0.5,0.5]$ con mucha precisi\'on $\beta^{-1} =25$
 \item Ajustar regresiones polinomiales de grado 0 hasta 9 con mucha incertidumbre a priori, ejemplo precisi\'on $\alpha^{-1}=10^-{7}$
\end{itemize}

\begin{figure}[H]
\centering
 \includegraphics[width=0.48\textwidth]{../../figures/model_selection_true_and_sample} 
 \includegraphics[width=0.48\textwidth]{../../figures/model_selection_MAP} 
\end{figure}

Luego,

\begin{itemize}
 \item Seleccionar modelo basado en la evidencia
 \item Comparar el comportamiento de la evidencia respecto al de m\'axima verosimilitud
\end{itemize}

\begin{figure}[H]     
     \centering 
     \begin{subfigure}[b]{0.47\textwidth}
       \includegraphics[width=1\textwidth]{../../figures/model_selection_evidence}
     \end{subfigure}
     \begin{subfigure}[b]{0.49\textwidth}
       \includegraphics[width=1\textwidth]{../../figures/model_selection_maxLikelihood}
     \end{subfigure}
\end{figure}


\subsection{La base de los algoritmos}\label{ssec:gaussiana}

La regresi\'on lineal mediante transformaciones no lineales se encuentra en la base de los algoritmos m\'as importantes del \'area de aprendizaje autom\'atico e inteligencia artificial, lo cuales pueden clasificarse del siguiente modo:
\begin{enumerate}
 \setlength\itemsep{-1mm}
 \item basadas en transformaciones no lineales fijas
 \item basadas en transformaciones no lineales adaptativas
 \item basadas en una jerarqu\'ia de transformaciones no lineales adaptativas
\end{enumerate}

Las redes neuronales profundas son un ejemplo de regresiones lineales basadas en una jerarqu\'ia de transformaciones adaptativas.
Comprender en profundidad la regresi\'on lineal b\'asica, aquella basada en transformaciones fijas, es de gran ayuda para comprender aspectos que surgen en los algoritmos de aprendizaje autom\'atico e inteligencia artificial.

\vspace{0.3cm}

Cuando estos modelos son instanciados con distribuciones Gaussianas multivariada, se tiene la siguiente propiedad\footnote{Para ver c\'omo se llega a este resultado, leer el cap\'itulo 2 del libro de Bishop ``Pattern Recognition and Machine Learning''}
 
\begin{framed}
Dado una distirbuci\'on Gaussiana marginal $p(\vm{x})$ y una distribuci\'on Gaussiana condicional en donde $P(\vm{y}|\vm{x})$ tiene como media una funci\'on lineal sobre $\vm{x}$.
\begin{align}
    P(\vm{x}) &=  \N(\vm{x}|\bm{\mu},\bm{\Lambda}^{-1}) \\
   P(\vm{y}|\vm{x}) &=  \N(\vm{y}|\vm{A}\vm{x}+\vm{b},\vm{L}^{-1})    
\end{align}


 Luego,  
\begin{align}
    P(\vm{y}) &=  \N(\vm{y}|\vm{A}\bm{\mu}+\vm{b},\, \vm{L}^{-1} + \vm{A}\vm{\Lambda}^{-1}\vm{A}^T) \\
   P(\vm{x}|\vm{y}) &=  \N(\vm{x}|\vm{\Sigma}[\vm{A}^T \vm{L}(\vm{y}-\vm{b})+ \bm{\Lambda\mu}],\,  \vm{\Sigma})\label{eq:post}
\end{align}

donde, 
\begin{equation}
 \vm{\Sigma} = (\vm{\Lambda} + \vm{A}^T \vm{LA} )^{-1}
\end{equation}
\end{framed}


\vspace{0.3cm}

Utilicen este resultado para derivar la evidencia y la posteriori del modelo lineal Bayesiano.

\newpage


\section{Anexo}

\subsection{M\'axima verosimilitud}

\begin{equation}\label{eq:maximum_likelihood}
 \begin{split}
   \text{log } p(\bm{t} | \bm{x}, \bm{w}, \beta) & = \sum_{i=1}^{n} \text{log } N(t_i | \bm{w}^T \bm{\phi}(\bm{x}_i), \sigma)  \\
  & =  \sum_{i=1}^{n} \text{log }  \frac{\sqrt{\beta} }{\sqrt{2\pi}} e^{\frac{-(t_i - \bm{w}^T\bm{\phi}(\bm{x}_i))^2}{2\beta^{-1}} } = \sum_{i=1}^{n} \text{log } \frac{\sqrt{\beta} }{\sqrt{2\pi}} + \sum_{i=1}^{n} \text{log } e^{\frac{-(t_i - \bm{w}^T\bm{\phi}(\bm{x}_i))^2}{2\beta^{-1}} } \\
  & = n \text{log } \frac{\sqrt{\beta} }{\sqrt{2\pi}} + \sum_{i=1}^{n} \text{log } e^{\frac{-(t_i - \bm{w}^T\bm{\phi}(\bm{x}_i))^2}{2\beta^{-1}} } = n \text{log } \frac{\sqrt{\beta} }{\sqrt{2\pi}} + \sum_{i=1}^{n}  \frac{-(t_i - \bm{w}^T\bm{\phi}(\bm{x}_i))^2}{2\beta^{-1}} \\
   &  = n \text{ log } \sqrt{\beta} - n \text{ log } \sqrt{2\pi} - \frac{\beta}{2} \sum_{i=1}^{n}  (t_i - \bm{w}^T\bm{\phi}(\bm{x}_i))^2   \\
  & \propto  - \sum_{i=1}^{n}  (t_i - \bm{w}^T\bm{\phi}(\bm{x}_i))^2 
 \end{split}
\end{equation}

\subsection{Multiplicaci\'on de normales}\label{multiplicacion_normales}

Luego, el problema que tenemos que resolver es
\begin{equation}
 \int N(x;\mu_1,\sigma_1^2)N(x;\mu_2,\sigma_2^2) dx
\end{equation}

Por defnici\'on,
\begin{equation}
\begin{split}
 N(x;y,\beta^2)N(x;\mu,\sigma^2) & = \frac{1}{\sqrt{2\pi}\sigma_1}e^{-\frac{(x-\mu_1)^2}{2\sigma_1^2}} \frac{1}{\sqrt{2\pi}\sigma_2}e^{-\frac{(x-\mu_2)^2}{2\sigma_2^2}}  \\
 & = \frac{1}{2\pi\sigma_1\sigma_2}\text{exp}\Bigg(-\underbrace{\left( \frac{(x-\mu_1)^2}{2\sigma_1^2} + \frac{(x-\mu_2)^2}{2\sigma_2^2} \right)}_{\theta} \Bigg)
\end{split}
\end{equation}

Luego,
\begin{equation}
 \theta = \frac{\sigma_2^2(x^2 + \mu_1^2 - 2x\mu_1) + \sigma_1^2(x^2 + \mu_2^2 - 2x\mu_2) }{2\sigma_1^2\sigma_2^2}
\end{equation}

Expando y reordeno los factores por potencias de $x$
\begin{equation}
 \frac{(\sigma_1^2 + \sigma_2^2) x^2 - (2\mu_1\sigma_2^2 + 2\mu_2\sigma_1^2) x + (\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2)}{2\sigma_1^2\sigma_2^2}
\end{equation}

Divido al numerador y el denominador por el factor de $x^2$
\begin{equation}
 \frac{x^2 - 2\frac{(\mu_1\sigma_2^2 + \mu_2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) } x + \frac{(\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) }}{2\frac{\sigma_1^2\sigma_2^2}{(\sigma_1^2 + \sigma_2^2)}}
\end{equation}

Esta ecuaci\'on es cuadr\'atica en x, y por lo tanto es proporcional a una funci\'on de densidad gausiana con desv\'io
\begin{equation}
\sigma_{\times} = \sqrt{\frac{\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2}}  
\end{equation}

y media
\begin{equation}
 \mu_{\times} = \frac{(\mu_1\sigma_2^2 + \mu_2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) }
\end{equation}

Dado que un t\'ermino $\varepsilon = 0$ puede ser agregado para completar el cuadrado en $\theta$, esta prueba es suficiente cuando no se necesita una normalizaci\'on.
Sea, 
\begin{equation}
 \varepsilon = \frac{\mu_{\times}^2-\mu_{\times}^2}{2\sigma_{\times}^2} = 0
\end{equation}

Al agregar este t\'ermino a $\theta$ tenemos
\begin{equation}
 \theta = \frac{x^2 - 2\mu_{\times}x + \mu_{\times}^2 }{2\sigma_{\times}^2} + \underbrace{\frac{ \frac{(\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) } - \mu_{\times}^2}{2\sigma_{\times}^2}}_{\varphi}
\end{equation}

Reorganizando el t\'ermino $\varphi$
\begin{equation}
\begin{split}
\varphi & = \frac{\frac{(\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) } - \left(\frac{(\mu_1\sigma_2^2 + \mu_2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) }\right)^2 }{2\frac{\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2}}  \\
& = \frac{(\sigma_1^2 + \sigma_2^2)(\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2) - (\mu_1\sigma_2^2 + \mu_2\sigma_1^2)^2}{\sigma_1^2 + \sigma_2^2}\frac{1}{2\sigma_1^2\sigma_2^2} \\[0.3cm]
& = \frac{(\mu_1^2\sigma_1^2\sigma_2^2 + \cancel{\mu_2^2\sigma_1^4} + \bcancel{\mu_1^2\sigma_2^4} + \mu_2^2\sigma_1^2\sigma_2^2) - (\bcancel{\mu_1^2\sigma_2^4} + 2\mu_1\mu_2\sigma_1^2\sigma_2^2 + \cancel{\mu_2^2\sigma_1^4} )}{\sigma_1^2 + \sigma_2^2}  \frac{1}{2\sigma_1^2\sigma_2^2} \\[0.3cm] 
& = \frac{(\sigma_1^2\sigma_2^2)(\mu_1^2 + \mu_2^2 - 2\mu_1\mu_2)}{\sigma_1^2 + \sigma_2^2}\frac{1}{2\sigma_1^2\sigma_2^2} = \frac{\mu_1^2 + \mu_2^2 - 2\mu_1\mu_2}{2(\sigma_1^2 + \sigma_2^2)} = \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)}
\end{split}
\end{equation}

Luego,
\begin{equation}
 \theta = \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} + \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} 
\end{equation}

Colocando esta forma de $\theta$ en su lugar
\begin{equation}
\begin{split}
 N(x;y,\beta^2)N(x;\mu,\sigma^2) & = \frac{1}{2\pi\sigma_1\sigma_2}\text{exp}\Bigg(-\underbrace{\left( \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} + \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} \right)}_{\theta} \Bigg) \\
 & = \frac{1}{2\pi\sigma_1\sigma_2}\text{exp}\left(  - \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} \right) \text{exp} \left( - \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} \right) 
\end{split}
\end{equation}

Multiplicando por $\sigma_{\times}\sigma_{\times}^{-1}$
\begin{equation}
\overbrace{\frac{\cancel{\sigma_1\sigma_2}}{\sqrt{\sigma_1^2+\sigma_2^2}}}^{\sigma_{\times}} \frac{1}{\sigma_{\times}} \frac{1}{2\pi\cancel{\sigma_1\sigma_2}}\text{exp}\left(  - \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} \right) \text{exp} \left( - \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} \right)
\end{equation}

Luego,
\begin{equation}
 \frac{1}{\sqrt{2\pi}\sigma_{\times}}\text{exp}\left(  - \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} \right) \frac{1}{\sqrt{2\pi(\sigma_1^2+\sigma_2^2)}} \text{exp} \left( - \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} \right)
\end{equation}

Retonando a la integral
\begin{equation}
\begin{split}
I & = \int N(x;\mu_{\times},\sigma_{\times}^2) \overbrace{N(\mu_1;\mu_2,\sigma_1^2 + \sigma_2^2)}^{\text{Escalar independiente de x}} dx \\[0.3cm]
& = N(\mu_1;\mu_2,\sigma_1^2 + \sigma_2^2) \underbrace{\int N(x,\mu_{\times},\sigma_{\times}^2)  dx}_{\text{Integra 1}} \\
& = N(\mu_1;\mu_2,\sigma_1^2 + \sigma_2^2)
\end{split}
\end{equation}




\end{document}
